<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="referrer" content="no-referrer"><!--!--><title>GPT-2中文聊天机器人：基于DialoGPT的双模型架构设计与实现 - Brahmacarya奇奇</title><link rel="manifest" href="/manifest.json"><meta name="theme-color" content="#1e88e5"><meta name="application-name" content="Brahmacarya奇奇"><meta name="msapplication-TileImage" content="/img/logo-192.png"><meta name="msapplication-TileColor" content="#1e88e5"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Brahmacarya奇奇"><meta name="apple-mobile-web-app-status-bar-style" content="default"><link rel="apple-touch-icon" sizes="192x192" href="/img/logo-192.png"><link rel="apple-touch-icon" sizes="512x512" href="/img/logo-512.png"><meta name="description" content="基于GPT-2架构的中文聊天机器人系统，采用DialoGPT的双模型设计理念，通过对话模型和互信息模型的协同工作，实现了高质量的中文对话生成。本文深入分析了系统的技术架构、核心算法实现以及优化策略。"><meta property="og:type" content="website"><meta property="og:title" content="GPT-2中文聊天机器人：基于DialoGPT的双模型架构设计与实现"><meta property="og:url" content="https://huangzhongqi978.top/2024/12/19/GPT2%E4%B8%AD%E6%96%87%E8%81%8A%E5%A4%A9%E6%9C%BA%E5%99%A8%E4%BA%BA%E6%8A%80%E6%9C%AF%E5%AE%9E%E7%8E%B0/"><meta property="og:site_name" content="Brahmacarya奇奇"><meta property="og:description" content="基于GPT-2架构的中文聊天机器人系统，采用DialoGPT的双模型设计理念，通过对话模型和互信息模型的协同工作，实现了高质量的中文对话生成。本文深入分析了系统的技术架构、核心算法实现以及优化策略。"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://gitee.com/huangzhongqi776/my-images/raw/master/20251004000139781.png"><meta property="article:published_time" content="2024-12-19T02:30:00.000Z"><meta property="article:modified_time" content="2025-10-03T16:03:06.108Z"><meta property="article:author" content="HuangZhongqi"><meta property="article:tag" content="深度学习"><meta property="article:tag" content="GPT-2"><meta property="article:tag" content="DialoGPT"><meta property="article:tag" content="中文对话"><meta property="article:tag" content="自然语言处理"><meta property="article:tag" content="互信息"><meta property="article:tag" content="对话生成"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="https://gitee.com/huangzhongqi776/my-images/raw/master/20251004000139781.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://huangzhongqi978.top/2024/12/19/GPT2%E4%B8%AD%E6%96%87%E8%81%8A%E5%A4%A9%E6%9C%BA%E5%99%A8%E4%BA%BA%E6%8A%80%E6%9C%AF%E5%AE%9E%E7%8E%B0/"},"headline":"GPT-2中文聊天机器人：基于DialoGPT的双模型架构设计与实现","image":["https://gitee.com/huangzhongqi776/my-images/raw/master/20251004000139781.png"],"datePublished":"2024-12-19T02:30:00.000Z","dateModified":"2025-10-03T16:03:06.108Z","author":{"@type":"Person","name":"HuangZhongqi"},"publisher":{"@type":"Organization","name":"Brahmacarya奇奇","logo":{"@type":"ImageObject","url":"https://huangzhongqi978.top/img/logo.svg"}},"description":"基于GPT-2架构的中文聊天机器人系统，采用DialoGPT的双模型设计理念，通过对话模型和互信息模型的协同工作，实现了高质量的中文对话生成。本文深入分析了系统的技术架构、核心算法实现以及优化策略。"}</script><link rel="canonical" href="https://huangzhongqi978.top/2024/12/19/GPT2%E4%B8%AD%E6%96%87%E8%81%8A%E5%A4%A9%E6%9C%BA%E5%99%A8%E4%BA%BA%E6%8A%80%E6%9C%AF%E5%AE%9E%E7%8E%B0/"><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.0.0/css/all.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link data-pjax rel="stylesheet" href="/css/default.css"><link rel="stylesheet" href="/css/modern-effects.css"><link rel="stylesheet" href="/css/dynamic-background.css"><link rel="stylesheet" href="/css/article-toc.css"><link rel="stylesheet" href="/css/fullscreen-reading.css"><link rel="stylesheet" href="/css/navbar-fix.css"><link rel="stylesheet" href="/css/article-actions.css"><link rel="stylesheet" href="/css/custom-layout.css"><link rel="stylesheet" href="/css/widget-toc.css"><link rel="stylesheet" href="/css/qq-qr-modal.css"><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.3.0"></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="Brahmacarya奇奇" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="GitHub" href="https://github.com/Huangzhongqi978"><i class="fab fa-github"></i></a><a class="navbar-item" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com/"><i class="fab fa-twitter"></i></a><a class="navbar-item" target="_blank" rel="noopener" title="LinkedIn" href="https://linkedin.com/in/huangzhongqi"><i class="fab fa-linkedin"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a><button class="theme-toggle-btn" id="theme-toggle" title="切换主题"><span class="icon"><i class="fas fa-moon" id="theme-icon"></i></span></button></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2024-12-19T02:30:00.000Z" title="2024/12/19 10:30:00">2024-12-19</time>发表</span><span class="level-item"><time dateTime="2025-10-03T16:03:06.108Z" title="2025/10/4 00:03:06">2025-10-04</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a><span> / </span><a class="link-muted" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/">自然语言处理</a><span> / </span><a class="link-muted" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/%E8%81%8A%E5%A4%A9%E6%9C%BA%E5%99%A8%E4%BA%BA/">聊天机器人</a></span><span class="level-item">15 分钟读完 (大约2229个字)</span></div></div><div class="article-title-container"><h1 class="title is-3 is-size-4-mobile">GPT-2中文聊天机器人：基于DialoGPT的双模型架构设计与实现</h1><div class="article-actions"><button class="button is-small is-ghost article-action-btn" id="article-toc-toggle" title="显示目录"><span class="icon"><i class="fas fa-list-ul"></i></span><span class="action-text">目录</span></button><button class="button is-small is-ghost article-action-btn" id="fullscreen-reading-btn" title="全屏阅读"><span class="icon"><i class="fas fa-expand"></i></span><span class="action-text">全屏</span></button></div></div><div class="content"><p>基于GPT-2架构的中文聊天机器人系统，采用DialoGPT的双模型设计理念，通过对话模型和互信息模型的协同工作，实现了高质量的中文对话生成。本文深入分析了系统的技术架构、核心算法实现以及优化策略。</p>
<span id="more"></span>

<h2 id="系统概述"><a href="#系统概述" class="headerlink" title="系统概述"></a>系统概述</h2><p>本系统基于微软DialoGPT论文的设计思想，构建了一个双模型架构的中文聊天机器人。系统核心创新在于引入互信息最大化（MMI）机制，通过对话模型生成多个候选响应，再使用MMI模型进行筛选，显著提升了对话质量和上下文连贯性。</p>
<h3 id="核心特性"><a href="#核心特性" class="headerlink" title="核心特性"></a>核心特性</h3><ul>
<li><strong>双模型架构</strong>：对话模型负责生成，MMI模型负责筛选</li>
<li><strong>中文优化</strong>：针对中文语言特点进行模型调优</li>
<li><strong>上下文感知</strong>：支持多轮对话历史管理</li>
<li><strong>智能采样</strong>：集成Top-k和Nucleus采样策略</li>
<li><strong>批量优化</strong>：支持批量生成和筛选机制</li>
</ul>
<h2 id="技术架构设计"><a href="#技术架构设计" class="headerlink" title="技术架构设计"></a>技术架构设计</h2><h3 id="系统架构图"><a href="#系统架构图" class="headerlink" title="系统架构图"></a>系统架构图</h3><p><img src="https://gitee.com/huangzhongqi776/my-images/raw/master/20251004000139781.png"></p>
<h3 id="核心组件分析"><a href="#核心组件分析" class="headerlink" title="核心组件分析"></a>核心组件分析</h3><h4 id="1-对话模型-Dialogue-Model"><a href="#1-对话模型-Dialogue-Model" class="headerlink" title="1. 对话模型 (Dialogue Model)"></a>1. 对话模型 (Dialogue Model)</h4><p>对话模型基于GPT-2架构，负责根据对话历史生成候选响应。其训练数据采用顺序拼接方式：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 对话模型训练数据格式</span>
<span class="token comment"># 输入: [CLS]用户1[SEP]机器人1[SEP]用户2[SEP]机器人2[SEP]</span>
<span class="token comment"># 目标: 学习预测下一个token</span>

<span class="token keyword">def</span> <span class="token function">preprocess_raw_data</span><span class="token punctuation">(</span>args<span class="token punctuation">,</span> tokenizer<span class="token punctuation">,</span> n_ctx<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    对话模型数据预处理
    将多轮对话按顺序拼接，构建训练样本
    """</span>
    dialogue_ids <span class="token operator">=</span> <span class="token punctuation">[</span>tokenizer<span class="token punctuation">.</span>cls_token_id<span class="token punctuation">]</span>  <span class="token comment"># 对话开始标记</span>
    <span class="token keyword">for</span> utterance <span class="token keyword">in</span> utterances<span class="token punctuation">:</span>
        <span class="token comment"># 将每个utterance转换为token ID</span>
        dialogue_ids<span class="token punctuation">.</span>extend<span class="token punctuation">(</span><span class="token punctuation">[</span>tokenizer<span class="token punctuation">.</span>convert_tokens_to_ids<span class="token punctuation">(</span>word<span class="token punctuation">)</span> <span class="token keyword">for</span> word <span class="token keyword">in</span> utterance<span class="token punctuation">]</span><span class="token punctuation">)</span>
        dialogue_ids<span class="token punctuation">.</span>append<span class="token punctuation">(</span>tokenizer<span class="token punctuation">.</span>sep_token_id<span class="token punctuation">)</span>  <span class="token comment"># 语句结束标记</span>
    <span class="token keyword">return</span> dialogue_ids<span class="token punctuation">[</span><span class="token punctuation">:</span>n_ctx<span class="token punctuation">]</span>  <span class="token comment"># 截断到最大长度</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h4 id="2-MMI模型-Maximum-Mutual-Information"><a href="#2-MMI模型-Maximum-Mutual-Information" class="headerlink" title="2. MMI模型 (Maximum Mutual Information)"></a>2. MMI模型 (Maximum Mutual Information)</h4><p>MMI模型同样基于GPT-2架构，但采用逆序拼接的训练方式，用于计算响应与对话历史的互信息：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">preprocess_mmi_raw_data</span><span class="token punctuation">(</span>args<span class="token punctuation">,</span> tokenizer<span class="token punctuation">,</span> n_ctx<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    MMI模型数据预处理
    将对话历史逆序拼接，学习P(Source|Response)
    """</span>
    dialogue_ids <span class="token operator">=</span> <span class="token punctuation">[</span>tokenizer<span class="token punctuation">.</span>cls_token_id<span class="token punctuation">]</span>
    <span class="token keyword">for</span> utterance <span class="token keyword">in</span> <span class="token builtin">reversed</span><span class="token punctuation">(</span>utterances<span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment"># 关键：逆序处理</span>
        dialogue_ids<span class="token punctuation">.</span>extend<span class="token punctuation">(</span><span class="token punctuation">[</span>tokenizer<span class="token punctuation">.</span>convert_tokens_to_ids<span class="token punctuation">(</span>word<span class="token punctuation">)</span> <span class="token keyword">for</span> word <span class="token keyword">in</span> utterance<span class="token punctuation">]</span><span class="token punctuation">)</span>
        dialogue_ids<span class="token punctuation">.</span>append<span class="token punctuation">(</span>tokenizer<span class="token punctuation">.</span>sep_token_id<span class="token punctuation">)</span>
    <span class="token keyword">return</span> dialogue_ids<span class="token punctuation">[</span><span class="token punctuation">:</span>n_ctx<span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h4 id="3-智能采样策略"><a href="#3-智能采样策略" class="headerlink" title="3. 智能采样策略"></a>3. 智能采样策略</h4><p>系统集成了多种采样策略，提升生成质量：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">top_k_top_p_filtering</span><span class="token punctuation">(</span>logits<span class="token punctuation">,</span> top_k<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span> top_p<span class="token operator">=</span><span class="token number">0.0</span><span class="token punctuation">,</span> filter_value<span class="token operator">=</span><span class="token operator">-</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token string">'Inf'</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    集成Top-k和Nucleus采样的过滤函数
    """</span>
    <span class="token comment"># Top-k采样：保留概率最高的k个token</span>
    <span class="token keyword">if</span> top_k <span class="token operator">></span> <span class="token number">0</span><span class="token punctuation">:</span>
        indices_to_remove <span class="token operator">=</span> logits <span class="token operator">&lt;</span> torch<span class="token punctuation">.</span>topk<span class="token punctuation">(</span>logits<span class="token punctuation">,</span> top_k<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">]</span>
        logits<span class="token punctuation">[</span>indices_to_remove<span class="token punctuation">]</span> <span class="token operator">=</span> filter_value
    
    <span class="token comment"># Nucleus采样：保留累积概率达到p的token集合</span>
    <span class="token keyword">if</span> top_p <span class="token operator">></span> <span class="token number">0.0</span><span class="token punctuation">:</span>
        sorted_logits<span class="token punctuation">,</span> sorted_indices <span class="token operator">=</span> torch<span class="token punctuation">.</span>sort<span class="token punctuation">(</span>logits<span class="token punctuation">,</span> descending<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
        cumulative_probs <span class="token operator">=</span> torch<span class="token punctuation">.</span>cumsum<span class="token punctuation">(</span>F<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>sorted_logits<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
        sorted_indices_to_remove <span class="token operator">=</span> cumulative_probs <span class="token operator">></span> top_p
        sorted_indices_to_remove<span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">=</span> sorted_indices_to_remove<span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>clone<span class="token punctuation">(</span><span class="token punctuation">)</span>
        sorted_indices_to_remove<span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0</span>
        indices_to_remove <span class="token operator">=</span> sorted_indices<span class="token punctuation">[</span>sorted_indices_to_remove<span class="token punctuation">]</span>
        logits<span class="token punctuation">[</span>indices_to_remove<span class="token punctuation">]</span> <span class="token operator">=</span> filter_value
    
    <span class="token keyword">return</span> logits<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h2 id="核心算法实现"><a href="#核心算法实现" class="headerlink" title="核心算法实现"></a>核心算法实现</h2><h3 id="1-对话生成流程"><a href="#1-对话生成流程" class="headerlink" title="1. 对话生成流程"></a>1. 对话生成流程</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">generate_response</span><span class="token punctuation">(</span>dialogue_model<span class="token punctuation">,</span> history<span class="token punctuation">,</span> tokenizer<span class="token punctuation">,</span> args<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    对话生成核心算法
    """</span>
    <span class="token comment"># 构建输入序列</span>
    input_ids <span class="token operator">=</span> <span class="token punctuation">[</span>tokenizer<span class="token punctuation">.</span>cls_token_id<span class="token punctuation">]</span>
    <span class="token keyword">for</span> history_utr <span class="token keyword">in</span> history<span class="token punctuation">[</span><span class="token operator">-</span>args<span class="token punctuation">.</span>max_history_len<span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
        input_ids<span class="token punctuation">.</span>extend<span class="token punctuation">(</span>history_utr<span class="token punctuation">)</span>
        input_ids<span class="token punctuation">.</span>append<span class="token punctuation">(</span>tokenizer<span class="token punctuation">.</span>sep_token_id<span class="token punctuation">)</span>
    
    <span class="token comment"># 自回归生成</span>
    generated <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    curr_input_tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>input_ids<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">long</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
    
    <span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>args<span class="token punctuation">.</span>max_len<span class="token punctuation">)</span><span class="token punctuation">:</span>
        outputs <span class="token operator">=</span> dialogue_model<span class="token punctuation">(</span>input_ids<span class="token operator">=</span>curr_input_tensor<span class="token punctuation">)</span>
        next_token_logits <span class="token operator">=</span> outputs<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>
        
        <span class="token comment"># 重复惩罚机制</span>
        <span class="token keyword">for</span> token_id <span class="token keyword">in</span> <span class="token builtin">set</span><span class="token punctuation">(</span>generated<span class="token punctuation">)</span><span class="token punctuation">:</span>
            next_token_logits<span class="token punctuation">[</span>token_id<span class="token punctuation">]</span> <span class="token operator">/=</span> args<span class="token punctuation">.</span>repetition_penalty
        
        <span class="token comment"># 应用采样策略</span>
        filtered_logits <span class="token operator">=</span> top_k_top_p_filtering<span class="token punctuation">(</span>
            next_token_logits<span class="token punctuation">,</span> 
            top_k<span class="token operator">=</span>args<span class="token punctuation">.</span>topk<span class="token punctuation">,</span> 
            top_p<span class="token operator">=</span>args<span class="token punctuation">.</span>topp
        <span class="token punctuation">)</span>
        
        <span class="token comment"># 采样下一个token</span>
        next_token <span class="token operator">=</span> torch<span class="token punctuation">.</span>multinomial<span class="token punctuation">(</span>
            F<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>filtered_logits<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> 
            num_samples<span class="token operator">=</span><span class="token number">1</span>
        <span class="token punctuation">)</span>
        
        <span class="token keyword">if</span> next_token <span class="token operator">==</span> tokenizer<span class="token punctuation">.</span>sep_token_id<span class="token punctuation">:</span>
            <span class="token keyword">break</span>
            
        generated<span class="token punctuation">.</span>append<span class="token punctuation">(</span>next_token<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        curr_input_tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>curr_input_tensor<span class="token punctuation">,</span> next_token<span class="token punctuation">)</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
    
    <span class="token keyword">return</span> generated<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="2-MMI筛选机制"><a href="#2-MMI筛选机制" class="headerlink" title="2. MMI筛选机制"></a>2. MMI筛选机制</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">mmi_selection</span><span class="token punctuation">(</span>candidate_responses<span class="token punctuation">,</span> history<span class="token punctuation">,</span> mmi_model<span class="token punctuation">,</span> tokenizer<span class="token punctuation">,</span> args<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    MMI模型筛选最优响应
    """</span>
    min_loss <span class="token operator">=</span> <span class="token builtin">float</span><span class="token punctuation">(</span><span class="token string">'Inf'</span><span class="token punctuation">)</span>
    best_response <span class="token operator">=</span> <span class="token string">""</span>
    
    <span class="token keyword">for</span> response <span class="token keyword">in</span> candidate_responses<span class="token punctuation">:</span>
        <span class="token comment"># 构建MMI模型输入（逆序拼接）</span>
        mmi_input_id <span class="token operator">=</span> <span class="token punctuation">[</span>tokenizer<span class="token punctuation">.</span>cls_token_id<span class="token punctuation">]</span>
        mmi_input_id<span class="token punctuation">.</span>extend<span class="token punctuation">(</span>response<span class="token punctuation">)</span>
        mmi_input_id<span class="token punctuation">.</span>append<span class="token punctuation">(</span>tokenizer<span class="token punctuation">.</span>sep_token_id<span class="token punctuation">)</span>
        
        <span class="token comment"># 逆序添加对话历史</span>
        <span class="token keyword">for</span> history_utr <span class="token keyword">in</span> <span class="token builtin">reversed</span><span class="token punctuation">(</span>history<span class="token punctuation">[</span><span class="token operator">-</span>args<span class="token punctuation">.</span>max_history_len<span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            mmi_input_id<span class="token punctuation">.</span>extend<span class="token punctuation">(</span>history_utr<span class="token punctuation">)</span>
            mmi_input_id<span class="token punctuation">.</span>append<span class="token punctuation">(</span>tokenizer<span class="token punctuation">.</span>sep_token_id<span class="token punctuation">)</span>
        
        <span class="token comment"># 计算互信息损失</span>
        mmi_input_tensor <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>mmi_input_id<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">long</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
        out <span class="token operator">=</span> mmi_model<span class="token punctuation">(</span>input_ids<span class="token operator">=</span>mmi_input_tensor<span class="token punctuation">,</span> labels<span class="token operator">=</span>mmi_input_tensor<span class="token punctuation">)</span>
        loss <span class="token operator">=</span> out<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
        
        <span class="token comment"># 选择损失最小的响应</span>
        <span class="token keyword">if</span> loss <span class="token operator">&lt;</span> min_loss<span class="token punctuation">:</span>
            best_response <span class="token operator">=</span> response
            min_loss <span class="token operator">=</span> loss
    
    <span class="token keyword">return</span> best_response<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="3-批量生成优化"><a href="#3-批量生成优化" class="headerlink" title="3. 批量生成优化"></a>3. 批量生成优化</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">batch_generate_responses</span><span class="token punctuation">(</span>dialogue_model<span class="token punctuation">,</span> history<span class="token punctuation">,</span> tokenizer<span class="token punctuation">,</span> args<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    批量生成多个候选响应，提升效率
    """</span>
    input_ids <span class="token operator">=</span> <span class="token punctuation">[</span>tokenizer<span class="token punctuation">.</span>cls_token_id<span class="token punctuation">]</span>
    <span class="token keyword">for</span> history_utr <span class="token keyword">in</span> history<span class="token punctuation">[</span><span class="token operator">-</span>args<span class="token punctuation">.</span>max_history_len<span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
        input_ids<span class="token punctuation">.</span>extend<span class="token punctuation">(</span>history_utr<span class="token punctuation">)</span>
        input_ids<span class="token punctuation">.</span>append<span class="token punctuation">(</span>tokenizer<span class="token punctuation">.</span>sep_token_id<span class="token punctuation">)</span>
    
    <span class="token comment"># 批量处理</span>
    batch_input_ids <span class="token operator">=</span> <span class="token punctuation">[</span>copy<span class="token punctuation">.</span>deepcopy<span class="token punctuation">(</span>input_ids<span class="token punctuation">)</span> <span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>args<span class="token punctuation">.</span>batch_size<span class="token punctuation">)</span><span class="token punctuation">]</span>
    curr_input_tensors <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>batch_input_ids<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">long</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
    
    generated <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    finish_set <span class="token operator">=</span> <span class="token builtin">set</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    
    <span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>args<span class="token punctuation">.</span>max_len<span class="token punctuation">)</span><span class="token punctuation">:</span>
        outputs <span class="token operator">=</span> dialogue_model<span class="token punctuation">(</span>input_ids<span class="token operator">=</span>curr_input_tensors<span class="token punctuation">)</span>
        next_token_logits <span class="token operator">=</span> outputs<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>
        
        <span class="token comment"># 批量应用重复惩罚</span>
        <span class="token keyword">for</span> index <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>args<span class="token punctuation">.</span>batch_size<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">for</span> token_id <span class="token keyword">in</span> <span class="token builtin">set</span><span class="token punctuation">(</span><span class="token punctuation">[</span>token_ids<span class="token punctuation">[</span>index<span class="token punctuation">]</span> <span class="token keyword">for</span> token_ids <span class="token keyword">in</span> generated<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                next_token_logits<span class="token punctuation">[</span>index<span class="token punctuation">]</span><span class="token punctuation">[</span>token_id<span class="token punctuation">]</span> <span class="token operator">/=</span> args<span class="token punctuation">.</span>repetition_penalty
        
        <span class="token comment"># 批量采样</span>
        filtered_logits <span class="token operator">=</span> top_k_top_p_filtering<span class="token punctuation">(</span>
            next_token_logits<span class="token punctuation">,</span> 
            top_k<span class="token operator">=</span>args<span class="token punctuation">.</span>topk<span class="token punctuation">,</span> 
            top_p<span class="token operator">=</span>args<span class="token punctuation">.</span>topp
        <span class="token punctuation">)</span>
        next_token <span class="token operator">=</span> torch<span class="token punctuation">.</span>multinomial<span class="token punctuation">(</span>
            F<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>filtered_logits<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> 
            num_samples<span class="token operator">=</span><span class="token number">1</span>
        <span class="token punctuation">)</span>
        
        <span class="token comment"># 检查生成完成状态</span>
        <span class="token keyword">for</span> index<span class="token punctuation">,</span> token_id <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>next_token<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">if</span> token_id <span class="token operator">==</span> tokenizer<span class="token punctuation">.</span>sep_token_id<span class="token punctuation">:</span>
                finish_set<span class="token punctuation">.</span>add<span class="token punctuation">(</span>index<span class="token punctuation">)</span>
        
        <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>finish_set<span class="token punctuation">)</span> <span class="token operator">==</span> args<span class="token punctuation">.</span>batch_size<span class="token punctuation">:</span>
            <span class="token keyword">break</span>
            
        generated<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">[</span>token<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">for</span> token <span class="token keyword">in</span> next_token<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        curr_input_tensors <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>curr_input_tensors<span class="token punctuation">,</span> next_token<span class="token punctuation">)</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
    
    <span class="token keyword">return</span> generated<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h2 id="模型配置与优化"><a href="#模型配置与优化" class="headerlink" title="模型配置与优化"></a>模型配置与优化</h2><h3 id="模型参数配置"><a href="#模型参数配置" class="headerlink" title="模型参数配置"></a>模型参数配置</h3><pre class="line-numbers language-json" data-language="json"><code class="language-json"><span class="token punctuation">&#123;</span>
  <span class="token property">"initializer_range"</span><span class="token operator">:</span> <span class="token number">0.02</span><span class="token punctuation">,</span>
  <span class="token property">"layer_norm_epsilon"</span><span class="token operator">:</span> <span class="token number">1e-05</span><span class="token punctuation">,</span>
  <span class="token property">"n_ctx"</span><span class="token operator">:</span> <span class="token number">300</span><span class="token punctuation">,</span>
  <span class="token property">"n_embd"</span><span class="token operator">:</span> <span class="token number">768</span><span class="token punctuation">,</span>
  <span class="token property">"n_head"</span><span class="token operator">:</span> <span class="token number">12</span><span class="token punctuation">,</span>
  <span class="token property">"n_layer"</span><span class="token operator">:</span> <span class="token number">10</span><span class="token punctuation">,</span>
  <span class="token property">"n_positions"</span><span class="token operator">:</span> <span class="token number">300</span><span class="token punctuation">,</span>
  <span class="token property">"vocab_size"</span><span class="token operator">:</span> <span class="token number">13317</span>
<span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h3 id="训练优化策略"><a href="#训练优化策略" class="headerlink" title="训练优化策略"></a>训练优化策略</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">calculate_loss_and_accuracy</span><span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> labels<span class="token punctuation">,</span> device<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    计算训练损失和准确率
    """</span>
    logits <span class="token operator">=</span> outputs<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
    shift_logits <span class="token operator">=</span> logits<span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span>contiguous<span class="token punctuation">(</span><span class="token punctuation">)</span>
    shift_labels <span class="token operator">=</span> labels<span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span>contiguous<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
    
    <span class="token comment"># 使用交叉熵损失，忽略PAD token</span>
    loss_fct <span class="token operator">=</span> CrossEntropyLoss<span class="token punctuation">(</span>ignore_index<span class="token operator">=</span>pad_id<span class="token punctuation">,</span> reduction<span class="token operator">=</span><span class="token string">'sum'</span><span class="token punctuation">)</span>
    loss <span class="token operator">=</span> loss_fct<span class="token punctuation">(</span>shift_logits<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> shift_logits<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                    shift_labels<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    
    <span class="token comment"># 计算准确率</span>
    _<span class="token punctuation">,</span> preds <span class="token operator">=</span> shift_logits<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
    not_ignore <span class="token operator">=</span> shift_labels<span class="token punctuation">.</span>ne<span class="token punctuation">(</span>pad_id<span class="token punctuation">)</span>
    num_targets <span class="token operator">=</span> not_ignore<span class="token punctuation">.</span><span class="token builtin">long</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
    correct <span class="token operator">=</span> <span class="token punctuation">(</span>shift_labels <span class="token operator">==</span> preds<span class="token punctuation">)</span> <span class="token operator">&amp;</span> not_ignore
    accuracy <span class="token operator">=</span> correct<span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">/</span> num_targets
    
    <span class="token keyword">return</span> loss <span class="token operator">/</span> num_targets<span class="token punctuation">,</span> accuracy<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h2 id="系统优化与亮点"><a href="#系统优化与亮点" class="headerlink" title="系统优化与亮点"></a>系统优化与亮点</h2><h3 id="1-内存优化"><a href="#1-内存优化" class="headerlink" title="1. 内存优化"></a>1. 内存优化</h3><ul>
<li><strong>梯度累积</strong>：支持大批量训练，减少显存占用</li>
<li><strong>动态截断</strong>：根据上下文长度动态调整输入序列</li>
<li><strong>缓存机制</strong>：优化重复计算，提升推理速度</li>
</ul>
<h3 id="2-生成质量优化"><a href="#2-生成质量优化" class="headerlink" title="2. 生成质量优化"></a>2. 生成质量优化</h3><ul>
<li><strong>重复惩罚</strong>：避免生成重复内容</li>
<li><strong>温度调节</strong>：控制生成的随机性</li>
<li><strong>上下文管理</strong>：维护对话历史，提升连贯性</li>
</ul>
<h3 id="3-工程化优化"><a href="#3-工程化优化" class="headerlink" title="3. 工程化优化"></a>3. 工程化优化</h3><ul>
<li><strong>多GPU支持</strong>：支持分布式训练和推理</li>
<li><strong>日志系统</strong>：完整的训练和推理日志</li>
<li><strong>配置管理</strong>：灵活的模型和训练参数配置</li>
</ul>
<h2 id="学习成果与技能总结"><a href="#学习成果与技能总结" class="headerlink" title="学习成果与技能总结"></a>学习成果与技能总结</h2><h3 id="核心技术掌握"><a href="#核心技术掌握" class="headerlink" title="核心技术掌握"></a>核心技术掌握</h3><ol>
<li><p><strong>GPT-2架构深入理解</strong></p>
<ul>
<li>Transformer解码器机制</li>
<li>自回归语言建模</li>
<li>注意力机制优化</li>
</ul>
</li>
<li><p><strong>对话系统设计</strong></p>
<ul>
<li>多轮对话建模</li>
<li>上下文管理策略</li>
<li>响应生成优化</li>
</ul>
</li>
<li><p><strong>互信息理论应用</strong></p>
<ul>
<li>MMI模型设计原理</li>
<li>候选响应筛选机制</li>
<li>质量评估指标</li>
</ul>
</li>
<li><p><strong>深度学习工程实践</strong></p>
<ul>
<li>模型训练优化</li>
<li>批量处理机制</li>
<li>内存管理策略</li>
</ul>
</li>
</ol>
<h3 id="系统亮点"><a href="#系统亮点" class="headerlink" title="系统亮点"></a>系统亮点</h3><ol>
<li><strong>创新架构设计</strong>：双模型协同工作，显著提升对话质量</li>
<li><strong>中文语言优化</strong>：针对中文特点进行模型调优</li>
<li><strong>工程化实现</strong>：完整的训练、推理和部署流程</li>
<li><strong>性能优化</strong>：支持批量处理和GPU加速</li>
<li><strong>可扩展性</strong>：模块化设计，易于功能扩展</li>
</ol>
<h2 id="技术展望"><a href="#技术展望" class="headerlink" title="技术展望"></a>技术展望</h2><h3 id="未来优化方向"><a href="#未来优化方向" class="headerlink" title="未来优化方向"></a>未来优化方向</h3><ol>
<li><strong>模型架构升级</strong>：探索更先进的预训练模型</li>
<li><strong>多模态支持</strong>：集成图像、语音等多模态输入</li>
<li><strong>个性化定制</strong>：支持用户个性化对话风格</li>
<li><strong>实时学习</strong>：实现在线学习和模型更新</li>
<li><strong>安全机制</strong>：增强内容安全和伦理约束</li>
</ol>
<h3 id="应用场景扩展"><a href="#应用场景扩展" class="headerlink" title="应用场景扩展"></a>应用场景扩展</h3><ul>
<li><strong>客服机器人</strong>：企业级客服自动化</li>
<li><strong>教育助手</strong>：个性化学习辅导</li>
<li><strong>娱乐聊天</strong>：智能社交机器人</li>
<li><strong>专业咨询</strong>：领域专家对话系统</li>
</ul>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本系统成功实现了基于GPT-2的中文聊天机器人，通过双模型架构和互信息筛选机制，在对话质量和上下文连贯性方面取得了显著提升。系统不仅具有完整的技术实现，还体现了深度学习在自然语言处理领域的工程化应用价值。</p>
<p>通过本项目的实践，深入掌握了GPT-2模型架构、对话系统设计、互信息理论应用等核心技术，为后续的NLP项目开发奠定了坚实基础。系统的模块化设计和优化策略也为大规模部署和功能扩展提供了良好的技术支撑。</p>
</div><div class="article-licensing box"><div class="licensing-title"><p>GPT-2中文聊天机器人：基于DialoGPT的双模型架构设计与实现</p><p><a href="https://huangzhongqi978.top/2024/12/19/GPT2中文聊天机器人技术实现/">https://huangzhongqi978.top/2024/12/19/GPT2中文聊天机器人技术实现/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>作者</h6><p>HuangZhongqi</p></div></div><div class="level-item is-narrow"><div><h6>发布于</h6><p>2024-12-19</p></div></div><div class="level-item is-narrow"><div><h6>更新于</h6><p>2025-10-04</p></div></div><div class="level-item is-narrow"><div><h6>许可协议</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons"></i></a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a><a class="link-muted mr-2" rel="tag" href="/tags/GPT-2/">GPT-2</a><a class="link-muted mr-2" rel="tag" href="/tags/DialoGPT/">DialoGPT</a><a class="link-muted mr-2" rel="tag" href="/tags/%E4%B8%AD%E6%96%87%E5%AF%B9%E8%AF%9D/">中文对话</a><a class="link-muted mr-2" rel="tag" href="/tags/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/">自然语言处理</a><a class="link-muted mr-2" rel="tag" href="/tags/%E4%BA%92%E4%BF%A1%E6%81%AF/">互信息</a><a class="link-muted mr-2" rel="tag" href="/tags/%E5%AF%B9%E8%AF%9D%E7%94%9F%E6%88%90/">对话生成</a></div><div class="sharethis-inline-share-buttons"></div><script src="https://platform-api.sharethis.com/js/sharethis.js#property=xxxx" defer></script></article></div><div class="card"><div class="card-content"><h3 class="menu-label has-text-centered">喜欢这篇文章？打赏一下作者吧</h3><div class="buttons is-centered"><a class="button donate" data-type="alipay"><span class="icon is-small"><i class="fab fa-alipay"></i></span><span>支付宝</span><span class="qrcode"><img src="/img/alipay-qrcode.png" alt="支付宝"></span></a><a class="button donate" data-type="wechat"><span class="icon is-small"><i class="fab fa-weixin"></i></span><span>微信</span><span class="qrcode"><img src="/img/wechat-qrcode.png" alt="微信"></span></a><a class="button donate" data-type="paypal" onclick="document.getElementById(&#039;paypal-donate-form&#039;).submit()"><span class="icon is-small"><i class="fab fa-paypal"></i></span><span>Paypal</span></a><form action="https://www.paypal.com/cgi-bin/webscr" method="post" target="_blank" rel="noopener" id="paypal-donate-form"><input type="hidden" name="cmd" value="_donations"><input type="hidden" name="business" value="huangzhongqi978@gmail.com"><input type="hidden" name="currency_code" value="USD"></form></div></div></div><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2024/12/19/ECAPA-TDNN%E5%A3%B0%E7%BA%B9%E8%AF%86%E5%88%AB%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">ECAPA-TDNN声纹识别系统设计与实现</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2024/12/19/%E6%8A%80%E6%9C%AF%E5%8D%9A%E5%AE%A2-%E5%BF%83%E7%90%86%E9%97%AE%E7%AD%94%E7%B3%BB%E7%BB%9F/"><span class="level-item">基于mT5的心理问答系统设计与实现</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">评论</h3><div id="disqus_thread"><noscript>Please enable JavaScript to view the <a target="_blank" rel="noopener" href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript></div><script>var disqus_config = function () {
            this.page.url = 'https://huangzhongqi978.top/2024/12/19/GPT2%E4%B8%AD%E6%96%87%E8%81%8A%E5%A4%A9%E6%9C%BA%E5%99%A8%E4%BA%BA%E6%8A%80%E6%9C%AF%E5%AE%9E%E7%8E%B0/';
            this.page.identifier = '2024/12/19/GPT2中文聊天机器人技术实现/';
        };
        (function() {
            var d = document, s = d.createElement('script');  
            s.src = '//' + 'huangzhongqi' + '.disqus.com/embed.js';
            s.setAttribute('data-timestamp', +new Date());
            (d.head || d.body).appendChild(s);
        })();</script></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1 is-sticky"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="https://images-1347279977.cos.ap-nanjing.myqcloud.com/ff71db1967b4c412f794ffe33ef624f.jpg" alt="HuangZhongqi"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">HuangZhongqi</p><p class="is-size-6 is-block">Deep Learning &amp; Computer Vision</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Shandong, China</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">文章</p><a href="/archives"><p class="title">12</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">分类</p><a href="/categories"><p class="title">19</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">标签</p><a href="/tags"><p class="title">47</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/Huangzhongqi978" target="_blank" rel="me noopener">关注我</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="me noopener" title="Github" href="https://github.com/Huangzhongqi978"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless qr-trigger" title="WeChat" href="javascript:void(0)" data-qr-src="https://images-1347279977.cos.ap-nanjing.myqcloud.com/14f8e0db9abd6ebb2aa256f5bb89225.png" data-qr-type="WeChat"><i class="fab fa-weixin"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="me noopener" title="LinkedIn" href="https://linkedin.com/in/huangzhongqi"><i class="fab fa-linkedin"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="me noopener" title="Email" href="mailto:huangzhongqi978@gmail.com"><i class="fas fa-envelope"></i></a><a class="level-item button is-transparent is-marginless qr-trigger" title="QQ" href="javascript:void(0)" data-qr-src="https://images-1347279977.cos.ap-nanjing.myqcloud.com/20251004151507271.png" data-qr-type="QQ"><i class="fab fa-qq"></i></a></div></div></div><div class="card widget" data-type="popular_posts"><div class="card-content"><div class="menu"><h3 class="menu-label">热门文章</h3><ul class="menu-list"><li><a class="level is-mobile" href="/2025/06/15/%E5%A9%9A%E6%81%8B%E7%B3%BB%E7%BB%9F%E6%8A%80%E6%9C%AF%E5%AE%9E%E7%8E%B0%E4%B8%8E%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/"><span class="level-start"><span class="level-item"><span class="icon"><i class="fas fa-fire" style="color: #ff6b35"></i></span></span><span class="level-item"><div><p class="has-text-weight-normal">基于Django+Vue的智能婚恋系统架构设计与技术实现</p><p class="is-size-7 has-text-grey"><time datetime="2025-06-15T02:30:00.000Z">2025-06-15</time></p></div></span></span><span class="level-end"><span class="has-text-grey is-size-7">Huangzhongqi978.top</span></span></a></li><li><a class="level is-mobile" href="/2024/12/24/EasyPan%E4%BA%91%E7%9B%98%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0/"><span class="level-start"><span class="level-item"><span class="icon"><i class="fas fa-fire" style="color: #ff8c42"></i></span></span><span class="level-item"><div><p class="has-text-weight-normal">EasyPan云盘系统设计与实现</p><p class="is-size-7 has-text-grey"><time datetime="2024-12-24T14:30:00.000Z">2024-12-24</time></p></div></span></span><span class="level-end"><span class="has-text-grey is-size-7">Huangzhongqi978.top</span></span></a></li><li><a class="level is-mobile" href="/2024/12/19/GPT2%E4%B8%AD%E6%96%87%E8%81%8A%E5%A4%A9%E6%9C%BA%E5%99%A8%E4%BA%BA%E6%8A%80%E6%9C%AF%E5%AE%9E%E7%8E%B0/"><span class="level-start"><span class="level-item"><span class="icon"><i class="fas fa-fire" style="color: #ffa726"></i></span></span><span class="level-item"><div><p class="has-text-weight-normal">GPT-2中文聊天机器人：基于DialoGPT的双模型架构设计与实现</p><p class="is-size-7 has-text-grey"><time datetime="2024-12-19T02:30:00.000Z">2024-12-19</time></p></div></span></span><span class="level-end"><span class="has-text-grey is-size-7">Huangzhongqi978.top</span></span></a></li></ul></div></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">归档</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2025/09/"><span class="level-start"><span class="level-item"><span class="icon"><i class="fas fa-calendar-alt"></i></span></span><span class="level-item"><span>9月 2025</span></span></span><span class="level-end"><span class="tag is-rounded is-light">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2025/07/"><span class="level-start"><span class="level-item"><span class="icon"><i class="fas fa-calendar-alt"></i></span></span><span class="level-item"><span>7月 2025</span></span></span><span class="level-end"><span class="tag is-rounded is-light">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2025/06/"><span class="level-start"><span class="level-item"><span class="icon"><i class="fas fa-calendar-alt"></i></span></span><span class="level-item"><span>6月 2025</span></span></span><span class="level-end"><span class="tag is-rounded is-light">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2025/01/"><span class="level-start"><span class="level-item"><span class="icon"><i class="fas fa-calendar-alt"></i></span></span><span class="level-item"><span>1月 2025</span></span></span><span class="level-end"><span class="tag is-rounded is-light">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/12/"><span class="level-start"><span class="level-item"><span class="icon"><i class="fas fa-calendar-alt"></i></span></span><span class="level-item"><span>12月 2024</span></span></span><span class="level-end"><span class="tag is-rounded is-light">5</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/10/"><span class="level-start"><span class="level-item"><span class="icon"><i class="fas fa-calendar-alt"></i></span></span><span class="level-item"><span>10月 2024</span></span></span><span class="level-end"><span class="tag is-rounded is-light">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/12/"><span class="level-start"><span class="level-item"><span class="icon"><i class="fas fa-calendar-alt"></i></span></span><span class="level-item"><span>12月 2023</span></span></span><span class="level-end"><span class="tag is-rounded is-light">1</span></span></a></li></ul></div></div></div><div class="column-right-shadow is-hidden-widescreen is-sticky"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3 is-sticky"><div class="card widget" data-type="recent_posts"><div class="card-content"><div class="menu"><h3 class="menu-label">最新文章</h3><ul class="menu-list"><li><a class="level is-mobile" href="/2025/09/10/Yolo11%E4%BA%A4%E9%80%9A%E6%A0%87%E5%BF%97%E6%A3%80%E6%B5%8B%E7%B3%BB%E7%BB%9F/"><span class="level-start"><span class="level-item"><span class="icon"><i class="fas fa-file-alt"></i></span></span><span class="level-item"><div><p class="has-text-weight-normal">Yolo11交通标志检测系统</p><p class="is-size-7 has-text-grey"><time datetime="2025-09-10T07:59:31.000Z">2025-09-10</time></p></div></span></span><span class="level-end"><span class="has-text-grey is-size-7">Huangzhongqi978.top</span></span></a></li><li><a class="level is-mobile" href="/2025/07/15/p2%E6%A3%80%E6%B5%8B%E5%A4%B4%E4%BA%A4%E9%80%9A%E6%A3%80%E6%B5%8B%E7%B3%BB%E7%BB%9F/"><span class="level-start"><span class="level-item"><span class="icon"><i class="fas fa-file-alt"></i></span></span><span class="level-item"><div><p class="has-text-weight-normal">添加P2检测头与SE机制的YOLOv8交通车辆与道路监检测系统优化</p><p class="is-size-7 has-text-grey"><time datetime="2025-07-14T16:00:00.000Z">2025-07-15</time></p></div></span></span><span class="level-end"><span class="has-text-grey is-size-7">Huangzhongqi978.top</span></span></a></li><li><a class="level is-mobile" href="/2025/06/15/%E5%A9%9A%E6%81%8B%E7%B3%BB%E7%BB%9F%E6%8A%80%E6%9C%AF%E5%AE%9E%E7%8E%B0%E4%B8%8E%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/"><span class="level-start"><span class="level-item"><span class="icon"><i class="fas fa-file-alt"></i></span></span><span class="level-item"><div><p class="has-text-weight-normal">基于Django+Vue的智能婚恋系统架构设计与技术实现</p><p class="is-size-7 has-text-grey"><time datetime="2025-06-15T02:30:00.000Z">2025-06-15</time></p></div></span></span><span class="level-end"><span class="has-text-grey is-size-7">Huangzhongqi978.top</span></span></a></li><li><a class="level is-mobile" href="/2025/01/27/AI%E6%99%BA%E8%83%BD%E7%AD%94%E9%A2%98%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0/"><span class="level-start"><span class="level-item"><span class="icon"><i class="fas fa-file-alt"></i></span></span><span class="level-item"><div><p class="has-text-weight-normal">AI智能答题系统设计与实现</p><p class="is-size-7 has-text-grey"><time datetime="2025-01-27T02:00:00.000Z">2025-01-27</time></p></div></span></span><span class="level-end"><span class="has-text-grey is-size-7">Huangzhongqi978.top</span></span></a></li><li><a class="level is-mobile" href="/2024/12/24/EasyPan%E4%BA%91%E7%9B%98%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0/"><span class="level-start"><span class="level-item"><span class="icon"><i class="fas fa-file-alt"></i></span></span><span class="level-item"><div><p class="has-text-weight-normal">EasyPan云盘系统设计与实现</p><p class="is-size-7 has-text-grey"><time datetime="2024-12-24T14:30:00.000Z">2024-12-24</time></p></div></span></span><span class="level-end"><span class="has-text-grey is-size-7">Huangzhongqi978.top</span></span></a></li></ul></div></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">分类</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/ego/"><span class="level-start"><span class="level-item">ego</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91/"><span class="level-start"><span class="level-item">后端开发</span></span><span class="level-end"><span class="level-item tag">1</span></span></a><ul><li><a class="level is-mobile" href="/categories/%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1/"><span class="level-start"><span class="level-item">系统设计</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%E6%8A%80%E6%9C%AF%E5%88%86%E4%BA%AB/"><span class="level-start"><span class="level-item">技术分享</span></span><span class="level-end"><span class="level-item tag">2</span></span></a><ul><li><a class="level is-mobile" href="/categories/%E6%8A%80%E6%9C%AF%E5%88%86%E4%BA%AB/%E5%85%A8%E6%A0%88%E5%BC%80%E5%8F%91/"><span class="level-start"><span class="level-item">全栈开发</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%8A%80%E6%9C%AF%E5%88%86%E4%BA%AB/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84/"><span class="level-start"><span class="level-item">微服务架构</span></span><span class="level-end"><span class="level-item tag">1</span></span></a><ul><li><a class="level is-mobile" href="/categories/%E6%8A%80%E6%9C%AF%E5%88%86%E4%BA%AB/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84/AI%E5%BA%94%E7%94%A8/"><span class="level-start"><span class="level-item">AI应用</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li></ul></li><li><a class="level is-mobile" href="/categories/%E6%95%99%E7%A8%8B/"><span class="level-start"><span class="level-item">教程</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"><span class="level-start"><span class="level-item">深度学习</span></span><span class="level-end"><span class="level-item tag">3</span></span></a><ul><li><a class="level is-mobile" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/NLP/"><span class="level-start"><span class="level-item">NLP</span></span><span class="level-end"><span class="level-item tag">1</span></span></a><ul><li><a class="level is-mobile" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/NLP/%E9%97%AE%E7%AD%94%E7%B3%BB%E7%BB%9F/"><span class="level-start"><span class="level-item">问答系统</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/"><span class="level-start"><span class="level-item">自然语言处理</span></span><span class="level-end"><span class="level-item tag">1</span></span></a><ul><li><a class="level is-mobile" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/%E8%81%8A%E5%A4%A9%E6%9C%BA%E5%99%A8%E4%BA%BA/"><span class="level-start"><span class="level-item">聊天机器人</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB/"><span class="level-start"><span class="level-item">语音识别</span></span><span class="level-end"><span class="level-item tag">1</span></span></a><ul><li><a class="level is-mobile" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"><span class="level-start"><span class="level-item">计算机视觉</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li></ul></li><li><a class="level is-mobile" href="/categories/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/"><span class="level-start"><span class="level-item">自然语言处理</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"><span class="level-start"><span class="level-item">计算机视觉</span></span><span class="level-end"><span class="level-item tag">3</span></span></a><ul><li><a class="level is-mobile" href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"><span class="level-start"><span class="level-item">深度学习</span></span><span class="level-end"><span class="level-item tag">1</span></span></a><ul><li><a class="level is-mobile" href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/"><span class="level-start"><span class="level-item">目标检测</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li></ul></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">标签</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/AI%E9%9B%86%E6%88%90/"><span class="tag">AI集成</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/DialoGPT/"><span class="tag">DialoGPT</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Django/"><span class="tag">Django</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ECAPA-TDNN/"><span class="tag">ECAPA-TDNN</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/GPT-2/"><span class="tag">GPT-2</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/GRU%E7%BB%93%E6%9E%84/"><span class="tag">GRU结构</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/GitHub/"><span class="tag">GitHub</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Gitee/"><span class="tag">Gitee</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/MinIO/"><span class="tag">MinIO</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/MySQL/"><span class="tag">MySQL</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/PicGo/"><span class="tag">PicGo</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/PyQt5/"><span class="tag">PyQt5</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Redis/"><span class="tag">Redis</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Spring-Boot/"><span class="tag">Spring Boot</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Spring-Cloud/"><span class="tag">Spring Cloud</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Vue-js/"><span class="tag">Vue.js</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/YOLOv8/"><span class="tag">YOLOv8</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/mT5/"><span class="tag">mT5</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/me/"><span class="tag">me</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/yolov8/"><span class="tag">yolov8</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/yolo%E6%A8%A1%E5%9E%8B/"><span class="tag">yolo模型</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E4%B8%AD%E6%96%87NLP/"><span class="tag">中文NLP</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E4%B8%AD%E6%96%87%E5%AF%B9%E8%AF%9D/"><span class="tag">中文对话</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E4%BA%91%E5%8E%9F%E7%94%9F/"><span class="tag">云原生</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E4%BA%91%E5%AD%98%E5%82%A8/"><span class="tag">云存储</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E4%BA%92%E4%BF%A1%E6%81%AF/"><span class="tag">互信息</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"><span class="tag">人工智能</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/"><span class="tag">分布式系统</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB/"><span class="tag">前后端分离</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%9B%BE%E5%BA%8A/"><span class="tag">图床</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%9B%BE%E6%95%B0%E6%8D%AE%E5%BA%93/"><span class="tag">图数据库</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%A3%B0%E7%BA%B9%E8%AF%86%E5%88%AB/"><span class="tag">声纹识别</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%A4%9A%E6%A8%A1%E6%80%81%E5%AF%B9%E8%AF%9D/"><span class="tag">多模态对话</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%AF%B9%E8%AF%9D%E7%94%9F%E6%88%90/"><span class="tag">对话生成</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84/"><span class="tag">微服务架构</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%BF%83%E7%90%86%E9%97%AE%E7%AD%94/"><span class="tag">心理问答</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86/"><span class="tag">文件管理</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%99%BA%E8%83%BD%E9%97%AE%E7%AD%94/"><span class="tag">智能问答</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%B5%B7%E5%85%B3%E7%9B%91%E7%AE%A1/"><span class="tag">海关监管</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"><span class="tag">深度学习</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96/"><span class="tag">特征提取</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/"><span class="tag">目标检测</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1/"><span class="tag">知识图谱</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84/"><span class="tag">系统架构</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/"><span class="tag">自然语言处理</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"><span class="tag">计算机视觉</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%AF%AD%E9%9F%B3%E5%A4%84%E7%90%86/"><span class="tag">语音处理</span><span class="tag">1</span></a></div></div></div></div></div><!--!--></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="Brahmacarya奇奇" height="28"></a><p class="is-size-7"><span>&copy; 2025 HuangZhongqi</span></p><p class="is-size-7">© 2025 Brahmacarya奇奇</p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="GitHub" href="https://github.com/Huangzhongqi978"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("zh-cn");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script><script data-particles-config type="application/json">{"particleCount":80,"particleColor":"#1e88e5","particleSize":2,"lineColor":"#1e88e5","lineWidth":1,"lineDistance":120,"speed":0.5,"opacity":0.6,"mobileOptimized":true,"interactive":true,"hoverEffect":true}</script></script><script data-pjax src="/js/column.js"></script><!--!--><script data-pjax src="/js/main.js" defer></script><script data-pjax src="/js/particles.js" defer></script><script data-pjax src="/js/modern-effects.js" defer></script><script data-pjax src="/js/dynamic-background.js" defer></script><script data-pjax src="/js/fullscreen-reading.js" defer></script><script data-pjax src="/js/widget-toc.js" defer></script><script data-pjax src="/js/article-toc.js" defer></script><script data-pjax src="/js/qq-qr-modal.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script></body></html>